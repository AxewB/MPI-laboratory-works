## Laboratory No1 (Shared variant). Запуск параллельной программы на различном числе одновременно работающих процессов, упорядочение вывода результатов.
1. Написать параллельную программу MPI, где каждый процесс определяет свой ранг MPI_Comm_rank (MPI_COMM_WORLD, &ProcRank);, после чего действия в программе разделяются. Все процессы, кроме процесса с рангом 0 else, передают значение своего ранга нулевому процессу MPI_Send (&ProcRank, 1, MPI_INT, 0, 0, MPI_COMM_WORLD);. Процесс с рангом 0 if ( ProcRank == 0 ){...} сначала печатает значение своего ранга printf ("\n Hello from process %3d", ProcRank);, а далее последовательно принимает сообщения с рангами процессов MPI_Recv(&RecvRank, 1, MPI_INT, MPI_ANY_SOURCE, MPI_ANY_TAG, MPI_COMM_WORLD, &Status); и также печатает их значения printf("\n Hello from process %3d", RecvRank); . При этом важно отметить, что порядок приема сообщений заранее не определен и зависит от условий выполнения параллельной программы (более того, этот порядок может изменяться от запуска к запуску). 
2.	Запустить программу на 1,2 … N процессах несколько раз.
3.	Проанализировать порядок вывода сообщений на экран. Вывести правило, определяющее порядок вывода сообщений.
4.	Построить график времени работы программы в зависимости от числа запущенных процессов от 1 до 16. Размер шага – например, 4.
5.	Построить график ускорения/замедления работы программы.
6.	Модифицировать программу таким образом, чтобы порядок вывода сообщений на экран соответствовал номеру соответствующего процесса.
7.	Нарисовать сеть Петри для двух вариантов MPI программы.

## Laboratory No2 (Variant 12). 
## Laboratory No3 (Variant 3). 
## Laboratory No4 (Variant 5). 
## Laboratory No5 (Variant 9). 
## Laboratory No6 (Variant 8). 
## Laboratory No7 (Variant 3). 


